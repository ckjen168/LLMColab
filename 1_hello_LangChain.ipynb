{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ckjen168/LLMColab/blob/main/1_hello_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Hello World\n",
        "Author: K. T. Lai <br>\n",
        "Date: 2025/1/9\n",
        "\n"
      ],
      "metadata": {
        "id": "mB7QCrz6oEba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intall LangChain"
      ],
      "metadata": {
        "id": "fIa_dAwtqyYB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAXTEq58QaK-",
        "outputId": "f45880a3-0766-4a5c-8579-4a3c420cbd34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/411.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m409.6/411.6 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/454.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install langchain --quiet\n",
        "!pip install langchain_openai --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 輸入 OpenAI keys (兩種方式)"
      ],
      "metadata": {
        "id": "YJ1YIG2Nq92M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用者輸入Key並存在全域變數 (Blocking)\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "fcocCJ-xRX9r",
        "outputId": "dc508972-3ec4-461d-b820-9dc6599b3a26"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-235109ee049a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter API key for OpenAI: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    832\u001b[0m             warnings.warn(\"The `stream` parameter of `getpass.getpass` will have no effect when using ipykernel\",\n\u001b[1;32m    833\u001b[0m                     UserWarning, stacklevel=2)\n\u001b[0;32m--> 834\u001b[0;31m         return self._input_request(prompt,\n\u001b[0m\u001b[1;32m    835\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 從Colab中讀取並存取全域變數\n",
        "from google.colab import userdata\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "tukAaspNryZW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use ChatOpenAI"
      ],
      "metadata": {
        "id": "x-zX487br_Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "id": "NQT7LXXNr35P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(\"Hello, world!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REQSYzRgVTXP",
        "outputId": "4533a09e-20d6-48d6-bfa3-80cd17ee5314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 11, 'total_tokens': 21, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'stop', 'logprobs': None}, id='run-6a31ce74-29a7-49cf-b423-29d3b43aba09-0', usage_metadata={'input_tokens': 11, 'output_tokens': 10, 'total_tokens': 21, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ret = model.invoke(\"用繁體中文自我介紹一下\")"
      ],
      "metadata": {
        "id": "K1iyVNx6VkCQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret.pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyFB2rlCVw5Y",
        "outputId": "04d875af-d926-4ac6-ca8b-9003432f6b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "你好！我是AI助手，專門用來回答問題和提供各類資訊。我能夠協助你解決問題、提供建議或是進行各種主題的討論。如果你有任何疑問或需要幫助的地方，隨時可以問我！很高興認識你！\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streaming Mode (串流模式)"
      ],
      "metadata": {
        "id": "aFwr30SVXiq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = model.stream(\"請介紹主要LangChain\")\n",
        "for chunk in chunks:\n",
        "    print(chunk.content, end=\"\", flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PpwYEONXgas",
        "outputId": "a46d0e3e-948a-47d9-cb09-371622167821"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain是一個旨在簡化和增強自然語言處理（NLP）模型的開發和應用的框架。它提供了一系列工具和功能，讓開發者能夠更輕鬆地構建基於語言模型的應用，無論是聊天機器人、自動化內容生成還是其他與語言相關的任務。\n",
            "\n",
            "以下是LangChain的一些主要特性和功能：\n",
            "\n",
            "1. **模組化設計**：LangChain將不同的功能模組化，開發者可以根據需求選擇性地集成每個模組。這包括數據連接模組、語言模型接口、記憶體管理等。\n",
            "\n",
            "2. **多種語言模型支持**：LangChain支持多種流行的語言模型，例如OpenAI的GPT、Hugging Face的模型等，允許開發者根據需求選擇合適的模型進行使用。\n",
            "\n",
            "3. **管道設計**：開發者可以構建複雜的工作流（pipeline），以便在不同的處理階段進行數據處理、語言生成和結果分析。\n",
            "\n",
            "4. **API集成**：LangChain允許與多種外部API進行集成，使得應用可以利用其他服務來增強功能。\n",
            "\n",
            "5. **記憶體功能**：提供記憶體管理，幫助應用在對話中保持上下文性，從而提高 user experience。\n",
            "\n",
            "6. **文檔和示例**：LangChain提供了豐富的文檔和示例，幫助開發者快速上手，並理解如何利用這個框架來構建應用。\n",
            "\n",
            "7. **社區支持**：LangChain擁有一個活躍的開發者社區，不斷更新和改進框架，提供支持与合作。\n",
            "\n",
            "總結來說，LangChain致力於使開發者能夠更高效地構建和部署語言應用，並利用最新的NLP技術來滿足實際需求。"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cache(快取) - 儲存以回答過的問題"
      ],
      "metadata": {
        "id": "zb65t48nYoM2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65W7-5FqlEnF",
        "outputId": "0a2626e0-7c6a-4928-e09e-2b2c2d1fa1e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.globals import set_llm_cache\n",
        "from langchain_community.cache import InMemoryCache\n",
        "\n",
        "set_llm_cache(InMemoryCache())"
      ],
      "metadata": {
        "id": "ACJYWVk-ZLGz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cache_model = ChatOpenAI(model=\"gpt-4o-mini\", cache=True)"
      ],
      "metadata": {
        "id": "DaVl8lejYnNL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 比較(有/無)Cache執行時間"
      ],
      "metadata": {
        "id": "jjP6YP-2lWTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "cache_model.invoke(\"請說今天的天氣\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbHgVzMPlP2m",
        "outputId": "6087c574-ac9f-4a8e-b0f4-fc44fc98cfb0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 32.3 ms, sys: 937 µs, total: 33.2 ms\n",
            "Wall time: 1.31 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='抱歉，我無法提供即時的天氣資訊。你可以查看天氣預報網站或使用手機的天氣應用來獲取當前的天氣情況。請告訴我其他我能幫助的事情！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 13, 'total_tokens': 69, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-6ebcf826-9c1c-45c1-86ee-b0e26909cbb0-0', usage_metadata={'input_tokens': 13, 'output_tokens': 56, 'total_tokens': 69, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "cache_model.invoke(\"請說今天的天氣\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zVrSKq8mGqi",
        "outputId": "ceea3cbe-5682-4257-eace-c6e14d4788a8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2.29 ms, sys: 0 ns, total: 2.29 ms\n",
            "Wall time: 2.14 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='抱歉，我無法提供即時的天氣資訊。你可以查看天氣預報網站或使用手機的天氣應用來獲取當前的天氣情況。請告訴我其他我能幫助的事情！', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 13, 'total_tokens': 69, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-6ebcf826-9c1c-45c1-86ee-b0e26909cbb0-0', usage_metadata={'input_tokens': 13, 'output_tokens': 56, 'total_tokens': 69, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 計算模型使用費用"
      ],
      "metadata": {
        "id": "HYqTSMDomuGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks import get_openai_callback\n",
        "\n",
        "with get_openai_callback() as cb:\n",
        "    result= cache_model.invoke(\"簡單介紹LangChain\")\n",
        "    print(result.content)\n",
        "    print(result.response_metadata['token_usage'])\n",
        "    print(result.id)\n",
        "    print(cb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZ96yjCwmxHa",
        "outputId": "9442b513-b21f-45e6-eed2-947d876220e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LangChain 是一個開源框架，旨在幫助開發者構建應用程序，利用大型語言模型（如 OpenAI 的 GPT 系列）進行文本生成、對話系統、數據分析等任務。它的設計重點是使開發者能夠更輕鬆地集成和部署這類模型，並提供了一些有用的工具和功能。\n",
            "\n",
            "LangChain 的主要特點包括：\n",
            "\n",
            "1. **模組化設計**：LangChain 提供了不同的組件，例如鏈（chains）、記憶（memory）、代理（agents）等，開發者可以根據需求組合這些組件來實現複雜的應用。\n",
            "\n",
            "2. **支持多種語言模型**：除了 OpenAI 的模型，LangChain 還支持其他流行的語言模型，這使得用戶可以根據需求選擇最合適的模型。\n",
            "\n",
            "3. **上下文管理**：LangChain 能夠管理上下文信息，使模型能夠記住之前的對話或資訊，從而提升交互的連貫性。\n",
            "\n",
            "4. **與外部數據源集成**：LangChain 可以與各種外部數據源（如 API、數據庫等）集成，讓模型能夠在有實時數據的情況下進行推理和生成。\n",
            "\n",
            "5. **對話流程設計**：開發者可以使用 LangChain 設計複雜的對話流程，並為用戶提供更加自然和流暢的交互體驗。\n",
            "\n",
            "總之，LangChain 是一個強大且靈活的工具，適合希望充分利用大型語言模型功能的開發者。\n",
            "{'completion_tokens': 389, 'prompt_tokens': 12, 'total_tokens': 401, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}\n",
            "run-24e924ce-d205-4531-bc24-e5b5a3a1bc57-0\n",
            "Tokens Used: 401\n",
            "\tPrompt Tokens: 12\n",
            "\t\tPrompt Tokens Cached: 0\n",
            "\tCompletion Tokens: 389\n",
            "\t\tReasoning Tokens: 0\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.00023519999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use Google Gemini\n",
        "\n",
        "[Reference](https://python.langchain.com/docs/integrations/chat/google_generative_ai/)\n",
        "\n",
        "[Gemini Pricing](https://ai.google.dev/pricing?hl=zh-tw#1_5flash)"
      ],
      "metadata": {
        "id": "-wpQAEMcCEVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6yRNN4VD8Zk",
        "outputId": "285ad566-c57a-471e-edb4-d7b703482749"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")"
      ],
      "metadata": {
        "id": "b763gDWGEXfS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "82wkkw4OnzvN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"說個關於AI的笑話\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHH1-a05DTAj",
        "outputId": "7ba83e55-accd-4884-87d0-d90ba7593065"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='為什麼AI過馬路？\\n\\n因為它被程式設計成要到達另一邊！', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-55fe8a2b-a01c-4982-aaff-afcb15995dcf-0', usage_metadata={'input_tokens': 7, 'output_tokens': 19, 'total_tokens': 26, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Safety Settings"
      ],
      "metadata": {
        "id": "X5hTRifEJ3Us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import (\n",
        "    ChatGoogleGenerativeAI,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        ")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-pro\",\n",
        "    safety_settings={\n",
        "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "dvZJyfRsJnd3"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}